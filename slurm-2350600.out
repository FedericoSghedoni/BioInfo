/homes/fsghedoni/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Dataset: rxrx1
Algorithm: ERM
Root dir: data
Split scheme: official
Dataset kwargs: {}
Download: False
Frac: 1.0
Version: None
Unlabeled split: None
Unlabeled version: None
Use unlabeled y: False
Loader kwargs: {'num_workers': 4, 'pin_memory': True}
Unlabeled loader kwargs: {'num_workers': 8, 'pin_memory': True}
Train loader: standard
Uniform over groups: False
Distinct groups: None
N groups per batch: 9
Unlabeled n groups per batch: None
Batch size: 16
Unlabeled batch size: None
Eval loader: standard
Gradient accumulation steps: 1
Model: google/vit-base-patch16-224
Model kwargs: {'pretrained': 'True,', 'hidden_dropout_prob': 0.01}
Noisystudent add dropout: None
Noisystudent dropout rate: None
Pretrained model path: None
Load featurizer only: False
Teacher model path: None
Transform: vit
Additional train transform: cutmix2
Target resolution: (256, 256)
Resize scale: None
Max token length: None
Randaugment n: 2
Loss function: cross_entropy
Loss kwargs: {}
Groupby fields: ['experiment']
Group dro step size: None
Coral penalty weight: 0.1
Dann penalty weight: None
Dann classifier lr: None
Dann featurizer lr: None
Dann discriminator lr: None
Afn penalty weight: None
Safn delta r: None
Hafn r: None
Use hafn: False
Irm lambda: 1.0
Irm penalty anneal iters: None
Self training lambda: None
Self training threshold: None
Pseudolabel t2: None
Soft pseudolabels: False
Algo log metric: accuracy
Process pseudolabels function: None
Val metric: acc_avg
Val metric decreasing: False
N epochs: 20
Optimizer: AdamW
Lr: 0.0002
Weight decay: 0.01
Max grad norm: 1.0
Optimizer kwargs: {}
Scheduler: linear_schedule_with_warmup
Scheduler kwargs: {'num_warmup_steps': 5415}
Scheduler metric split: val
Scheduler metric name: None
Process outputs function: multiclass_logits_to_pred
Evaluate all splits: True
Eval splits: []
Eval only: False
Eval epoch: None
Device: cuda
Seed: 0
Log dir: ./logz_dropout
Log every: 50
Save step: None
Save best: True
Save last: True
Save pred: True
No group logging: False
Progress bar: False
Resume: True
Use wandb: False
Wandb api key path: None
Wandb kwargs: {}
Use data parallel: False

Train data...
    experiment = HEPG2-08: n = 0
    experiment = HEPG2-09: n = 0
    experiment = HEPG2-10: n = 0
    experiment = HEPG2-11: n = 0
    experiment = HUVEC-17: n = 0
    experiment = HUVEC-18: n = 0
    experiment = HUVEC-19: n = 0
    experiment = HUVEC-20: n = 0
    experiment = HUVEC-21: n = 0
    experiment = HUVEC-22: n = 0
    experiment = HUVEC-23: n = 0
    experiment = HUVEC-24: n = 0
    experiment = RPE-08: n = 0
    experiment = RPE-09: n = 0
    experiment = RPE-10: n = 0
    experiment = RPE-11: n = 0
    experiment = U2OS-04: n = 0
    experiment = U2OS-05: n = 0
    experiment = HEPG2-01: n = 1232
    experiment = HEPG2-02: n = 1232
    experiment = HEPG2-03: n = 1232
    experiment = HEPG2-04: n = 1232
    experiment = HEPG2-05: n = 1232
    experiment = HEPG2-06: n = 1232
    experiment = HEPG2-07: n = 1230
    experiment = HUVEC-01: n = 1232
    experiment = HUVEC-02: n = 1232
    experiment = HUVEC-03: n = 1232
    experiment = HUVEC-04: n = 1232
    experiment = HUVEC-05: n = 1232
    experiment = HUVEC-06: n = 1231
    experiment = HUVEC-07: n = 1232
    experiment = HUVEC-08: n = 1232
    experiment = HUVEC-09: n = 1232
    experiment = HUVEC-10: n = 1232
    experiment = HUVEC-11: n = 1232
    experiment = HUVEC-12: n = 1232
    experiment = HUVEC-13: n = 1224
    experiment = HUVEC-14: n = 1216
    experiment = HUVEC-15: n = 1216
    experiment = HUVEC-16: n = 1232
    experiment = RPE-01: n = 1232
    experiment = RPE-02: n = 1232
    experiment = RPE-03: n = 1232
    experiment = RPE-04: n = 1231
    experiment = RPE-05: n = 1232
    experiment = RPE-06: n = 1232
    experiment = RPE-07: n = 1232
    experiment = U2OS-01: n = 1232
    experiment = U2OS-02: n = 1232
    experiment = U2OS-03: n = 1232
Validation (OOD) data...
    experiment = HEPG2-08: n = 2462
    experiment = HEPG2-09: n = 0
    experiment = HEPG2-10: n = 0
    experiment = HEPG2-11: n = 0
    experiment = HUVEC-17: n = 0
    experiment = HUVEC-18: n = 0
    experiment = HUVEC-19: n = 0
    experiment = HUVEC-20: n = 2464
    experiment = HUVEC-21: n = 0
    experiment = HUVEC-22: n = 0
    experiment = HUVEC-23: n = 0
    experiment = HUVEC-24: n = 0
    experiment = RPE-08: n = 0
    experiment = RPE-09: n = 2462
    experiment = RPE-10: n = 0
    experiment = RPE-11: n = 0
    experiment = U2OS-04: n = 0
    experiment = U2OS-05: n = 2440
    experiment = HEPG2-01: n = 0
    experiment = HEPG2-02: n = 0
    experiment = HEPG2-03: n = 0
    experiment = HEPG2-04: n = 0
    experiment = HEPG2-05: n = 0
    experiment = HEPG2-06: n = 0
    experiment = HEPG2-07: n = 0
    experiment = HUVEC-01: n = 0
    experiment = HUVEC-02: n = 0
    experiment = HUVEC-03: n = 0
    experiment = HUVEC-04: n = 0
    experiment = HUVEC-05: n = 0
    experiment = HUVEC-06: n = 0
    experiment = HUVEC-07: n = 0
    experiment = HUVEC-08: n = 0
    experiment = HUVEC-09: n = 0
    experiment = HUVEC-10: n = 0
    experiment = HUVEC-11: n = 0
    experiment = HUVEC-12: n = 0
    experiment = HUVEC-13: n = 0
    experiment = HUVEC-14: n = 0
    experiment = HUVEC-15: n = 0
    experiment = HUVEC-16: n = 0
    experiment = RPE-01: n = 0
    experiment = RPE-02: n = 0
    experiment = RPE-03: n = 0
    experiment = RPE-04: n = 0
    experiment = RPE-05: n = 0
    experiment = RPE-06: n = 0
    experiment = RPE-07: n = 0
    experiment = U2OS-01: n = 0
    experiment = U2OS-02: n = 0
    experiment = U2OS-03: n = 0
Test (OOD) data...
    experiment = HEPG2-08: n = 0
    experiment = HEPG2-09: n = 2464
    experiment = HEPG2-10: n = 2464
    experiment = HEPG2-11: n = 2460
    experiment = HUVEC-17: n = 2464
    experiment = HUVEC-18: n = 2462
    experiment = HUVEC-19: n = 2464
    experiment = HUVEC-20: n = 0
    experiment = HUVEC-21: n = 2464
    experiment = HUVEC-22: n = 2464
    experiment = HUVEC-23: n = 2462
    experiment = HUVEC-24: n = 2464
    experiment = RPE-08: n = 2464
    experiment = RPE-09: n = 0
    experiment = RPE-10: n = 2464
    experiment = RPE-11: n = 2434
    experiment = U2OS-04: n = 2464
    experiment = U2OS-05: n = 0
    experiment = HEPG2-01: n = 0
    experiment = HEPG2-02: n = 0
    experiment = HEPG2-03: n = 0
    experiment = HEPG2-04: n = 0
    experiment = HEPG2-05: n = 0
    experiment = HEPG2-06: n = 0
    experiment = HEPG2-07: n = 0
    experiment = HUVEC-01: n = 0
    experiment = HUVEC-02: n = 0
    experiment = HUVEC-03: n = 0
    experiment = HUVEC-04: n = 0
    experiment = HUVEC-05: n = 0
    experiment = HUVEC-06: n = 0
    experiment = HUVEC-07: n = 0
    experiment = HUVEC-08: n = 0
    experiment = HUVEC-09: n = 0
    experiment = HUVEC-10: n = 0
    experiment = HUVEC-11: n = 0
    experiment = HUVEC-12: n = 0
    experiment = HUVEC-13: n = 0
    experiment = HUVEC-14: n = 0
    experiment = HUVEC-15: n = 0
    experiment = HUVEC-16: n = 0
    experiment = RPE-01: n = 0
    experiment = RPE-02: n = 0
    experiment = RPE-03: n = 0
    experiment = RPE-04: n = 0
    experiment = RPE-05: n = 0
    experiment = RPE-06: n = 0
    experiment = RPE-07: n = 0
    experiment = U2OS-01: n = 0
    experiment = U2OS-02: n = 0
    experiment = U2OS-03: n = 0
Test (ID) data...
    experiment = HEPG2-08: n = 0
    experiment = HEPG2-09: n = 0
    experiment = HEPG2-10: n = 0
    experiment = HEPG2-11: n = 0
    experiment = HUVEC-17: n = 0
    experiment = HUVEC-18: n = 0
    experiment = HUVEC-19: n = 0
    experiment = HUVEC-20: n = 0
    experiment = HUVEC-21: n = 0
    experiment = HUVEC-22: n = 0
    experiment = HUVEC-23: n = 0
    experiment = HUVEC-24: n = 0
    experiment = RPE-08: n = 0
    experiment = RPE-09: n = 0
    experiment = RPE-10: n = 0
    experiment = RPE-11: n = 0
    experiment = U2OS-04: n = 0
    experiment = U2OS-05: n = 0
    experiment = HEPG2-01: n = 1232
    experiment = HEPG2-02: n = 1232
    experiment = HEPG2-03: n = 1232
    experiment = HEPG2-04: n = 1232
    experiment = HEPG2-05: n = 1232
    experiment = HEPG2-06: n = 1232
    experiment = HEPG2-07: n = 1230
    experiment = HUVEC-01: n = 1232
    experiment = HUVEC-02: n = 1232
    experiment = HUVEC-03: n = 1232
    experiment = HUVEC-04: n = 1232
    experiment = HUVEC-05: n = 1232
    experiment = HUVEC-06: n = 1231
    experiment = HUVEC-07: n = 1232
    experiment = HUVEC-08: n = 1232
    experiment = HUVEC-09: n = 1232
    experiment = HUVEC-10: n = 1232
    experiment = HUVEC-11: n = 1232
    experiment = HUVEC-12: n = 1232
    experiment = HUVEC-13: n = 1224
    experiment = HUVEC-14: n = 1216
    experiment = HUVEC-15: n = 1216
    experiment = HUVEC-16: n = 1232
    experiment = RPE-01: n = 1232
    experiment = RPE-02: n = 1232
    experiment = RPE-03: n = 1232
    experiment = RPE-04: n = 1231
    experiment = RPE-05: n = 1232
    experiment = RPE-06: n = 1232
    experiment = RPE-07: n = 1232
    experiment = U2OS-01: n = 1232
    experiment = U2OS-02: n = 1232
    experiment = U2OS-03: n = 1232
Some weights of ViTClassifier were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:
- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([1139]) in the model instantiated
- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([1139, 768]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/homes/fsghedoni/.local/lib/python3.9/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Resuming from epoch 17 with best val metric 0.24684575200080872
Epoch [17]:

Train:
