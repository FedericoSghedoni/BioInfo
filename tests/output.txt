0. Running command for hyperparameters (16, 0.001, 0.01, 'num_warmup_steps=0'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.001 --weight_decay 0.01 --scheduler_kwargs num_warmup_steps=0
1. Running command for hyperparameters (16, 0.001, 0.01, 'num_warmup_steps=5415'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.001 --weight_decay 0.01 --scheduler_kwargs num_warmup_steps=5415
0. Running command for hyperparameters (16, 0.001, 0.01, 'num_warmup_steps=5415'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume True --model google/vit-base-patch16-224 --batch_size 16 --lr 0.001 --weight_decay 0.01 --scheduler_kwargs num_warmup_steps=5415
0. Running command for hyperparameters (16, 0.001, 0.01, 'num_warmup_steps=5415'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume True --model google/vit-base-patch16-224 --batch_size 16 --lr 0.001 --weight_decay 0.01 --scheduler_kwargs num_warmup_steps=5415
1. Running command for hyperparameters (16, 0.001, 0.01, 'num_warmup_steps=10000'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.001 --weight_decay 0.01 --scheduler_kwargs num_warmup_steps=10000
2. Running command for hyperparameters (16, 0.001, 0.001, 'num_warmup_steps=5415'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.001 --weight_decay 0.001 --scheduler_kwargs num_warmup_steps=5415
3. Running command for hyperparameters (16, 0.001, 0.001, 'num_warmup_steps=10000'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.001 --weight_decay 0.001 --scheduler_kwargs num_warmup_steps=10000
4. Running command for hyperparameters (16, 0.001, 1e-05, 'num_warmup_steps=5415'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.001 --weight_decay 1e-05 --scheduler_kwargs num_warmup_steps=5415
4. Running command for hyperparameters (16, 0.001, 1e-05, 'num_warmup_steps=5415'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume True --model google/vit-base-patch16-224 --batch_size 16 --lr 0.001 --weight_decay 1e-05 --scheduler_kwargs num_warmup_steps=5415
5. Running command for hyperparameters (16, 0.001, 1e-05, 'num_warmup_steps=10000'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.001 --weight_decay 1e-05 --scheduler_kwargs num_warmup_steps=10000
6. Running command for hyperparameters (16, 0.0002, 0.01, 'num_warmup_steps=5415'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0002 --weight_decay 0.01 --scheduler_kwargs num_warmup_steps=5415
7. Running command for hyperparameters (16, 0.0002, 0.01, 'num_warmup_steps=10000'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0002 --weight_decay 0.01 --scheduler_kwargs num_warmup_steps=10000
8. Running command for hyperparameters (16, 0.0002, 0.001, 'num_warmup_steps=5415'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0002 --weight_decay 0.001 --scheduler_kwargs num_warmup_steps=5415
8. Running command for hyperparameters (16, 0.0002, 0.001, 'num_warmup_steps=5415'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume True --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0002 --weight_decay 0.001 --scheduler_kwargs num_warmup_steps=5415
9. Running command for hyperparameters (16, 0.0002, 0.001, 'num_warmup_steps=10000'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0002 --weight_decay 0.001 --scheduler_kwargs num_warmup_steps=10000
9. Running command for hyperparameters (16, 0.0002, 0.001, 'num_warmup_steps=10000'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume True --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0002 --weight_decay 0.001 --scheduler_kwargs num_warmup_steps=10000
9. Running command for hyperparameters (16, 0.0002, 0.001, 'num_warmup_steps=10000'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume True --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0002 --weight_decay 0.001 --scheduler_kwargs num_warmup_steps=10000
9. Running command for hyperparameters (16, 0.0002, 0.001, 'num_warmup_steps=10000'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume True --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0002 --weight_decay 0.001 --scheduler_kwargs num_warmup_steps=10000
9. Running command for hyperparameters (16, 0.0002, 0.001, 'num_warmup_steps=10000'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume True --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0002 --weight_decay 0.001 --scheduler_kwargs num_warmup_steps=10000
9. Running command for hyperparameters (16, 0.0002, 0.001, 'num_warmup_steps=10000'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume True --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0002 --weight_decay 0.001 --scheduler_kwargs num_warmup_steps=10000
10. Running command for hyperparameters (16, 0.0002, 1e-05, 'num_warmup_steps=5415'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0002 --weight_decay 1e-05 --scheduler_kwargs num_warmup_steps=5415
11. Running command for hyperparameters (16, 0.0002, 1e-05, 'num_warmup_steps=10000'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0002 --weight_decay 1e-05 --scheduler_kwargs num_warmup_steps=10000
11. Running command for hyperparameters (16, 0.0002, 1e-05, 'num_warmup_steps=10000'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume True --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0002 --weight_decay 1e-05 --scheduler_kwargs num_warmup_steps=10000
12. Running command for hyperparameters (16, 0.0001, 0.01, 'num_warmup_steps=5415'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0001 --weight_decay 0.01 --scheduler_kwargs num_warmup_steps=5415
13. Running command for hyperparameters (16, 0.0001, 0.01, 'num_warmup_steps=10000'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0001 --weight_decay 0.01 --scheduler_kwargs num_warmup_steps=10000
14. Running command for hyperparameters (16, 0.0001, 0.001, 'num_warmup_steps=5415'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0001 --weight_decay 0.001 --scheduler_kwargs num_warmup_steps=5415
15. Running command for hyperparameters (16, 0.0001, 0.001, 'num_warmup_steps=10000'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0001 --weight_decay 0.001 --scheduler_kwargs num_warmup_steps=10000
16. Running command for hyperparameters (16, 0.0001, 1e-05, 'num_warmup_steps=5415'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0001 --weight_decay 1e-05 --scheduler_kwargs num_warmup_steps=5415
17. Running command for hyperparameters (16, 0.0001, 1e-05, 'num_warmup_steps=10000'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume False --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0001 --weight_decay 1e-05 --scheduler_kwargs num_warmup_steps=10000
17. Running command for hyperparameters (16, 0.0001, 1e-05, 'num_warmup_steps=10000'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume True --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0001 --weight_decay 1e-05 --scheduler_kwargs num_warmup_steps=10000
17. Running command for hyperparameters (16, 0.0001, 1e-05, 'num_warmup_steps=10000'): python WildsDataset/examples/run_expt.py --dataset rxrx1 --algorithm ERM --root_dir data --device 0 --resume True --model google/vit-base-patch16-224 --batch_size 16 --lr 0.0001 --weight_decay 1e-05 --scheduler_kwargs num_warmup_steps=10000
